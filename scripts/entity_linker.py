#!/usr/bin/env python3
"""
Entity Linker Script - Normalize ‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞‡πÅ‡∏•‡∏∞ map ‡∏Å‡∏±‡∏ö series

‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö:
- Link ‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞‡∏Å‡∏±‡∏ö AniList ID
- ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó research_items ‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ link
- ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏•‡∏∞ verify ‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞

‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô:
    # Link ‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
    python scripts/entity_linker.py --link "Attack on Titan"
    
    # Link ‡∏´‡∏•‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠
    python scripts/entity_linker.py --link "AOT" "Demon Slayer" "One Piece"
    
    # ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó research_items ‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ link
    python scripts/entity_linker.py --update-db
    
    # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞
    python scripts/entity_linker.py --search "Frieren"
    
    # ‡∏î‡∏π aliases ‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö
    python scripts/entity_linker.py --list-aliases
    
    # ‡πÄ‡∏û‡∏¥‡πà‡∏° alias ‡πÉ‡∏´‡∏°‡πà
    python scripts/entity_linker.py --add-alias "bnha" "Boku no Hero Academia"
"""

import sys
import argparse
from pathlib import Path
from datetime import datetime
from typing import List

# ‡πÄ‡∏û‡∏¥‡πà‡∏° project root ‡πÉ‡∏ô path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from rich.console import Console
from rich.table import Table
from rich.progress import Progress, SpinnerColumn, TextColumn

from src.db.connection import init_db, session_scope
from src.db.repository import ResearchItemRepository
from src.anime.anilist import AniListClient
from src.anime.entity_linker import EntityLinker, LinkedEntity
from src.utils.config import load_config
from src.utils.logger import get_logger

console = Console()
logger = get_logger(__name__)


def parse_args():
    """Parse command line arguments"""
    parser = argparse.ArgumentParser(
        description="Normalize ‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞‡πÅ‡∏•‡∏∞ map ‡∏Å‡∏±‡∏ö series",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô:
  %(prog)s --link "Attack on Titan"       Link ‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
  %(prog)s --link "AOT" "JJK"             Link ‡∏´‡∏•‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠
  %(prog)s --update-db                    ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó research_items
  %(prog)s --search "Frieren"             ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞
  %(prog)s --list-aliases                 ‡∏î‡∏π aliases ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        """
    )
    
    # Actions
    action_group = parser.add_argument_group("‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô")
    action_group.add_argument(
        "--link",
        nargs="+",
        metavar="TITLE",
        help="Link ‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞‡∏Å‡∏±‡∏ö AniList"
    )
    action_group.add_argument(
        "--search",
        type=str,
        metavar="QUERY",
        help="‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞‡πÉ‡∏ô AniList"
    )
    action_group.add_argument(
        "--update-db",
        action="store_true",
        help="‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó research_items ‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ link"
    )
    action_group.add_argument(
        "--extract",
        type=str,
        metavar="TEXT",
        help="‡∏î‡∏∂‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°"
    )
    
    # Alias management
    alias_group = parser.add_argument_group("‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Aliases")
    alias_group.add_argument(
        "--list-aliases",
        action="store_true",
        help="‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ aliases ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"
    )
    alias_group.add_argument(
        "--add-alias",
        nargs=2,
        metavar=("ALIAS", "FULL_NAME"),
        help="‡πÄ‡∏û‡∏¥‡πà‡∏° alias ‡πÉ‡∏´‡∏°‡πà"
    )
    
    # Cache management
    cache_group = parser.add_argument_group("‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Cache")
    cache_group.add_argument(
        "--clear-cache",
        action="store_true",
        help="‡∏•‡πâ‡∏≤‡∏á entity cache"
    )
    cache_group.add_argument(
        "--cache-stats",
        action="store_true",
        help="‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥ cache"
    )
    
    # Options
    options_group = parser.add_argument_group("‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å")
    options_group.add_argument(
        "--no-cache",
        action="store_true",
        help="‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ cache"
    )
    options_group.add_argument(
        "--min-confidence",
        type=float,
        default=0.6,
        help="‡∏Ñ‡πà‡∏≤ confidence ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥ (default: 0.6)"
    )
    options_group.add_argument(
        "--limit",
        type=int,
        default=100,
        help="‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö --update-db (default: 100)"
    )
    options_group.add_argument(
        "--verbose", "-v",
        action="store_true",
        help="‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°"
    )
    
    return parser.parse_args()


def display_linked_entity(entity: LinkedEntity, verbose: bool = False):
    """‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå LinkedEntity"""
    # Color based on confidence
    if entity.confidence >= 0.9:
        color = "green"
    elif entity.confidence >= 0.7:
        color = "yellow"
    else:
        color = "red"
    
    console.print(f"\n[bold]{entity.original_text}[/bold]")
    console.print(f"  ‚îú‚îÄ Normalized: [{color}]{entity.normalized_title}[/{color}]")
    console.print(f"  ‚îú‚îÄ Confidence: [{color}]{entity.confidence:.2%}[/{color}] ({entity.match_type})")
    
    if entity.anilist_id:
        console.print(f"  ‚îú‚îÄ AniList ID: {entity.anilist_id}")
        console.print(f"  ‚îî‚îÄ URL: https://anilist.co/anime/{entity.anilist_id}")
    else:
        console.print(f"  ‚îî‚îÄ [dim]‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ô AniList[/dim]")
    
    if verbose and entity.anime_data:
        data = entity.anime_data
        console.print(f"\n  [dim]‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î:[/dim]")
        if data.get("genres"):
            console.print(f"    Genres: {', '.join(data['genres'])}")
        if data.get("average_score"):
            console.print(f"    Score: {data['average_score']}/100")
        if data.get("popularity"):
            console.print(f"    Popularity: {data['popularity']:,}")
        if data.get("status"):
            console.print(f"    Status: {data['status']}")


def link_titles(titles: List[str], linker: EntityLinker, verbose: bool = False):
    """Link ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞"""
    console.print(f"\n[bold cyan]üîó ‡∏Å‡∏≥‡∏•‡∏±‡∏á link {len(titles)} ‡∏ä‡∏∑‡πà‡∏≠...[/bold cyan]")
    
    results = linker.link_entities(titles)
    
    for entity in results:
        display_linked_entity(entity, verbose)
    
    # Summary
    linked = sum(1 for e in results if e.anilist_id)
    console.print(f"\n[bold]‡∏™‡∏£‡∏∏‡∏õ: Link ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à {linked}/{len(results)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£[/bold]")


def search_anime(query: str, verbose: bool = False):
    """‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞‡πÉ‡∏ô AniList"""
    console.print(f"\n[bold cyan]üîé ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤: {query}[/bold cyan]")
    
    client = AniListClient()
    results = client.search_anime(query, limit=10)
    
    if not results:
        console.print("[yellow]‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå[/yellow]")
        return
    
    table = Table(title="‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤")
    table.add_column("ID", style="cyan")
    table.add_column("Title (EN)", style="green")
    table.add_column("Title (JP)", style="dim")
    table.add_column("Format")
    table.add_column("Score")
    table.add_column("Status")
    
    for anime in results:
        table.add_row(
            str(anime.anilist_id),
            anime.title_english or "-",
            anime.title_romaji or "-",
            anime.format or "-",
            f"{anime.average_score}/100" if anime.average_score else "-",
            anime.status or "-",
        )
    
    console.print(table)


def extract_entities(text: str, linker: EntityLinker, verbose: bool = False):
    """‡∏î‡∏∂‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°"""
    console.print(f"\n[bold cyan]üìù ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á entities ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°...[/bold cyan]")
    console.print(f"[dim]‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: {text[:200]}{'...' if len(text) > 200 else ''}[/dim]")
    
    # Extract without linking first
    entities = linker.extract_entities(text)
    
    if not entities:
        console.print("[yellow]‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°[/yellow]")
        return
    
    console.print(f"\n[green]‡∏û‡∏ö {len(entities)} entities:[/green]")
    for entity in entities:
        console.print(f"  ‚Ä¢ {entity}")
    
    # Link entities
    console.print("\n[cyan]‡∏Å‡∏≥‡∏•‡∏±‡∏á link entities...[/cyan]")
    linked = linker.link_entities(entities)
    
    for entity in linked:
        display_linked_entity(entity, verbose)


def update_database(linker: EntityLinker, limit: int = 100, verbose: bool = False):
    """‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó research_items ‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ link"""
    console.print(f"\n[bold cyan]üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó research_items...[/bold cyan]")
    
    config = load_config()
    init_db(config.database.path)
    
    with session_scope() as session:
        repo = ResearchItemRepository(session)
        
        # Get unlinked items
        from sqlalchemy import select
        from src.db.models import ResearchItem
        
        stmt = (
            select(ResearchItem)
            .where(ResearchItem.is_linked == False)
            .where(ResearchItem.source.like("rss_%"))
            .limit(limit)
        )
        
        items = session.scalars(stmt).all()
        
        if not items:
            console.print("[green]‚úÖ ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó[/green]")
            return
        
        console.print(f"[dim]‡∏û‡∏ö {len(items)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ link[/dim]")
        
        updated = 0
        
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=console,
        ) as progress:
            task = progress.add_task("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó...", total=len(items))
            
            for item in items:
                # Extract and link entities from title and content
                text = f"{item.title} {item.content or ''}"
                linked = linker.extract_and_link(text)
                
                if linked:
                    # Update item
                    item.entities = {"anime_titles": [e.original_text for e in linked]}
                    item.linked_series = [e.to_dict() for e in linked if e.anilist_id]
                    item.is_linked = bool(item.linked_series)
                    
                    if item.is_linked:
                        updated += 1
                        if verbose:
                            console.print(f"  [green]‚úì[/green] {item.title[:50]}...")
                
                progress.advance(task)
        
        session.commit()
        console.print(f"\n[bold green]‚úÖ ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {updated}/{len(items)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£[/bold green]")


def list_aliases(linker: EntityLinker):
    """‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ aliases ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"""
    aliases = linker.get_aliases()
    
    table = Table(title="Anime Aliases")
    table.add_column("Alias", style="cyan")
    table.add_column("Full Name", style="green")
    
    for alias, full_name in sorted(aliases.items()):
        table.add_row(alias, full_name)
    
    console.print(table)
    console.print(f"\n[dim]‡∏£‡∏ß‡∏° {len(aliases)} aliases[/dim]")


def main():
    """Main function"""
    args = parse_args()
    
    # Create linker
    linker = EntityLinker(min_confidence=args.min_confidence)
    
    # Handle cache operations
    if args.clear_cache:
        linker.clear_cache()
        return 0
    
    if args.cache_stats:
        stats = linker.get_cache_stats()
        console.print("\n[bold]Cache Statistics[/bold]")
        for key, value in stats.items():
            console.print(f"  {key}: {value}")
        return 0
    
    # Handle alias operations
    if args.list_aliases:
        list_aliases(linker)
        return 0
    
    if args.add_alias:
        alias, full_name = args.add_alias
        linker.add_alias(alias, full_name)
        return 0
    
    # Handle main operations
    use_cache = not args.no_cache
    
    if args.link:
        link_titles(args.link, linker, args.verbose)
        return 0
    
    if args.search:
        search_anime(args.search, args.verbose)
        return 0
    
    if args.extract:
        extract_entities(args.extract, linker, args.verbose)
        return 0
    
    if args.update_db:
        update_database(linker, args.limit, args.verbose)
        return 0
    
    # No action specified
    console.print("[yellow]‚ö†Ô∏è ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏∞‡∏ö‡∏∏‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô (--link, --search, --update-db, --extract)[/yellow]")
    console.print("[dim]‡πÉ‡∏ä‡πâ --help ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô[/dim]")
    return 1


if __name__ == "__main__":
    sys.exit(main())
